\relax 
\citation{las}
\citation{ctc}
\citation{rnnt}
\citation{w2v}
\citation{bert}
\citation{w2v}
\citation{mel2vec}
\citation{w2v_c}
\citation{beam}
\citation{chime4}
\citation{multi_las1}
\citation{multi_las2}
\citation{multi_las3}
\citation{multi_las4}
\citation{multi_tt}
\citation{bf_g}
\citation{multi_tt}
\citation{t_t1}
\citation{t_t2}
\citation{conformer}
\citation{mask_bf}
\citation{mask_bf2}
\citation{frame}
\citation{multi_tt}
\citation{chime4}
\citation{transformer}
\citation{rnnt}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2} Background}{1}}
\newlabel{sec:back}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Multi-channel neural transducer}{1}}
\newlabel{sec:t-t}{{2.1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of multi-channel neural transducer in the case of two channels.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:transducer}{{1}{1}}
\citation{transformer}
\citation{conformer}
\citation{w2v}
\citation{mel2vec}
\citation{conformer}
\citation{cos_ipd}
\newlabel{eq:loss}{{1}{2}}
\newlabel{eq:prob}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} Self-supervised learning based on wav2vec 2.0 framework}{2}}
\newlabel{sec:contrastive_loss}{{2.2}{2}}
\newlabel{eq:cont_loss}{{3}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3} Self-supervised learning for multi-channel neural transducer}{2}}
\newlabel{proposed}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Joint quantization}{2}}
\newlabel{proposed0}{{3.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Joint quantization in the case of two channels.\relax }}{2}}
\newlabel{fig:p1}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} Feature-wise quantization}{2}}
\newlabel{proposed1}{{3.2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} Channel-wise quantization}{2}}
\newlabel{proposed2}{{3.3}{2}}
\newlabel{eq:attention}{{4}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {4} Experiments}{2}}
\newlabel{sec:experiment}{{4}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1} Data preparation}{2}}
\newlabel{sec:corpus}{{4.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2} Model details}{2}}
\newlabel{sec:archtec}{{4.2}{2}}
\citation{specaugment}
\citation{transformer}
\citation{adam}
\citation{torch}
\citation{swish}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Feature-wise quantization.\relax }}{3}}
\newlabel{fig:p2}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Channel-wise quantization.\relax }}{3}}
\newlabel{fig:p3}{{4}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \unhbox \voidb@x \hbox {Multi-channel} Conformer encoder architecture.\relax }}{3}}
\newlabel{tab:conformer}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3} Results}{3}}
\newlabel{sec:results}{{4.3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1} Far-field in-house dataset}{3}}
\newlabel{sec:far}{{4.3.1}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The result of feature-wise quantization on \unhbox \voidb@x \hbox {far-field in-house} dataset. Results are given as relative character error rate reduction (CERR) [\%]. The plus sign indicates improvement.\relax }}{3}}
\newlabel{tab:result_1}{{2}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The result of channel-wise quantization on \unhbox \voidb@x \hbox {far-field in-house} dataset. Results are given as relative character error rate reduction (CERR) [\%]. The plus sign indicates improvement.\relax }}{3}}
\newlabel{tab:result_2}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2} CHiME-4 dataset}{3}}
\newlabel{sec:chime4}{{4.3.2}{3}}
\citation{chime4}
\bibcite{las}{1}
\bibcite{ctc}{2}
\bibcite{rnnt}{3}
\bibcite{w2v}{4}
\bibcite{bert}{5}
\bibcite{mel2vec}{6}
\bibcite{w2v_c}{7}
\bibcite{beam}{8}
\bibcite{chime4}{9}
\bibcite{multi_las1}{10}
\bibcite{multi_las2}{11}
\bibcite{multi_las3}{12}
\bibcite{multi_las4}{13}
\bibcite{multi_tt}{14}
\bibcite{bf_g}{15}
\bibcite{t_t1}{16}
\bibcite{t_t2}{17}
\bibcite{conformer}{18}
\bibcite{mask_bf}{19}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The result of feature-wise quantization on \unhbox \voidb@x \hbox {CHiME-4} dataset. Results are given as relative character error rate reduction (CERR) [\%] and relative word error rate reduction (WERR) [\%]. The plus sign indicates improvement.\relax }}{4}}
\newlabel{tab:result_3}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4} Analysis of hidden vectors}{4}}
\newlabel{sec:analyze_hidden}{{4.4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Analysis of hidden vectors after self-supervised learning.\relax }}{4}}
\newlabel{fig:ssl}{{5}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {5} Conclusion}{4}}
\newlabel{sec:conclution}{{5}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {6} References}{4}}
\bibcite{mask_bf2}{20}
\bibcite{frame}{21}
\bibcite{transformer}{22}
\bibcite{cos_ipd}{23}
\bibcite{specaugment}{24}
\bibcite{adam}{25}
\bibcite{torch}{26}
\bibcite{swish}{27}
